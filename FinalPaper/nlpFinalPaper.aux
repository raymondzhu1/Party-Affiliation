\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\citation{thomas2006get}
\citation{pedregosa2011scikit}
\citation{thomas2006get}
\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction}{1}{section.1}}
\@writefile{toc}{\contentsline {section}{\numberline {2}Related Works}{1}{section.2}}
\newlabel{gen_inst}{{2}{1}{Related Works}{section.2}{}}
\citation{yu2008classifying}
\citation{iyyer2014political}
\citation{pedregosa2011scikit}
\@writefile{toc}{\contentsline {section}{\numberline {3}Data}{3}{section.3}}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Zipf's Law}}{4}{figure.1}}
\newlabel{fig: zip}{{1}{4}{Zipf's Law}{figure.1}{}}
\newlabel{Most and Least Common Words}{{3}{4}{Data}{figure.1}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4}Method}{4}{section.4}}
\citation{pedregosa2011scikit}
\@writefile{toc}{\contentsline {section}{\numberline {5}Proposed Solution and Experiments}{5}{section.5}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.1}Optimal Preprocessing}{5}{subsection.5.1}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.1.1}Unigram vs. Bigram Language Model}{5}{subsubsection.5.1.1}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.1.2}Tf-Idf Weighting}{5}{subsubsection.5.1.2}}
\citation{pedregosa2011scikit}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.2}Classifiers and Hyperparameters}{6}{subsection.5.2}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.2.1}Multinomial Naive Bayes Experiments}{6}{subsubsection.5.2.1}}
\citation{pedregosa2011scikit}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.2.2}Stochastic Gradient Descent Experiments}{7}{subsubsection.5.2.2}}
\@writefile{toc}{\contentsline {section}{\numberline {6}Experiments and Results}{7}{section.6}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.1}Baseline Algorithms}{7}{subsection.6.1}}
\bibstyle{plain}
\bibdata{nlpFinal}
\bibcite{iyyer2014political}{1}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.2}Optimal Preprocessing}{8}{subsection.6.2}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Tf-Idf On vs. Off for SGDClassifier with Varied Loss Functions}}{8}{figure.2}}
\newlabel{fig: tfidf}{{2}{8}{Tf-Idf On vs. Off for SGDClassifier with Varied Loss Functions}{figure.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Unigram vs. Bigram for SGDClassifier with Varied Loss Functions}}{8}{figure.3}}
\newlabel{fig: lm}{{3}{8}{Unigram vs. Bigram for SGDClassifier with Varied Loss Functions}{figure.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.3}Optimal Hyper-parameters and Results}{8}{subsection.6.3}}
\bibcite{pedregosa2011scikit}{2}
\bibcite{thomas2006get}{3}
\bibcite{yu2008classifying}{4}
